{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "PATH = os.getcwd()\n",
    "\n",
    "# Cotton Plant image dataset path deffinition in local devices\n",
    "data_path = PATH + '/train-new'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "img_rows=128\n",
    "img_cols=128\n",
    "num_channel=3\n",
    "num_epoch=100\n",
    "\n",
    "# Class number deffinition in cotton plant dataset\n",
    "num_classes = 4\n",
    "\n",
    "img_data_list=[]\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "\timg_list=os.listdir(data_path+'/'+ dataset)\n",
    "\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "\tfor img in img_list:\n",
    "\t\tinput_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "\t\tinput_img_resize=cv2.resize(input_img,(128,128))\n",
    "\t\timg_data_list.append(input_img_resize)\n",
    "\n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "print (img_data.shape)\n",
    "\n",
    "if num_channel==1:\n",
    "\tif K.image_data_format()=='th':\n",
    "\t\timg_data= np.expand_dims(img_data, axis=1) \n",
    "\t\tprint (img_data.shape)\n",
    "\telse:\n",
    "\t\timg_data= np.expand_dims(img_data, axis=4) \n",
    "\t\tprint (img_data.shape)\n",
    "\t\t\n",
    "else:\n",
    "\tif K.image_data_format()=='th':\n",
    "\t\timg_data=np.rollaxis(img_data,3,1)\n",
    "\t\tprint (img_data.shape)\n",
    "        \n",
    "# Labels Assinment\n",
    "# Define the number of classes\n",
    "num_classes = 4\n",
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "labels[0:600]=0\n",
    "labels[600:1200]=1\n",
    "labels[1200:1800]=2\n",
    "labels[1800:2400]=3\n",
    "names = ['Bacterial_blight','healthy','leaf_minor','spidermit'] \n",
    "\n",
    "# convert class labels to on-hot encoding\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "\n",
    "# Dataset Reshaffling\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# Defining the model(CNN)\n",
    "input_shape=img_data[0].shape\n",
    "\t\t\t\t\t\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3,3,border_mode='same',input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n",
    "\n",
    "# Viewing model configuration \n",
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\t\t\t\n",
    "model.layers[0].output_shape\t\t\t\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable\n",
    "# Model Training\n",
    "hist = model.fit(X_train, y_train, batch_size=32, nb_epoch=num_epoch, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# visualizing losses and accuracy of model\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['acc']\n",
    "val_acc=hist.history['val_acc']\n",
    "xc=range(100)\n",
    "plt.figure(1,figsize=(7,5))\n",
    "plt.plot(xc,train_loss)\n",
    "plt.plot(xc,val_loss)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'])\n",
    "plt.style.use(['classic'])\n",
    "plt.figure(2,figsize=(7,5))\n",
    "plt.plot(xc,train_acc)\n",
    "plt.plot(xc,val_acc)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('train_acc vs val_acc')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'],loc=4)\n",
    "plt.style.use(['classic'])\n",
    "\n",
    "# Evaluating the model performance\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "test_image = X_test[0:1]\n",
    "print (test_image.shape)\n",
    "print(model.predict(test_image))\n",
    "print(model.predict_classes(test_image))\n",
    "print(y_test[0:1])\n",
    "\n",
    "# Testing a new image of cotton\n",
    "test_image = cv2.imread('1.jpg')\n",
    "test_image=cv2.resize(test_image,(128,128))\n",
    "test_image = np.array(test_image)\n",
    "test_image = test_image.astype('float32')\n",
    "test_image /= 255\n",
    "print (test_image.shape)\n",
    "   \n",
    "if num_channel==1:\n",
    "\tif K.image_data_format()=='th':\n",
    "\t\ttest_image= np.expand_dims(test_image, axis=0)\n",
    "\t\ttest_image= np.expand_dims(test_image, axis=0)\n",
    "\t\tprint (test_image.shape)\n",
    "\telse:\n",
    "\t\ttest_image= np.expand_dims(test_image, axis=3) \n",
    "\t\ttest_image= np.expand_dims(test_image, axis=0)\n",
    "\t\tprint (test_image.shape)\n",
    "\t\t\n",
    "else:\n",
    "\tif K.image_data_format()=='th':\n",
    "\t\ttest_image=np.rollaxis(test_image,2,0)\n",
    "\t\ttest_image= np.expand_dims(test_image, axis=0)\n",
    "\t\tprint (test_image.shape)\n",
    "\telse:\n",
    "\t\ttest_image= np.expand_dims(test_image, axis=0)\n",
    "\t\tprint (test_image.shape)\n",
    "\n",
    "# Predicting the test image of cotton leaf\n",
    "print((model.predict(test_image)))\n",
    "print(model.predict_classes(test_image))\n",
    "\n",
    "# Visualizing the intermediate layer\n",
    "def get_featuremaps(model, layer_idx, X_batch):\n",
    "\tget_activations = K.function([model.layers[0].input, K.learning_phase()],[model.layers[layer_idx].output,])\n",
    "\tactivations = get_activations([X_batch,0])\n",
    "\treturn activations\n",
    "layer_num=1\n",
    "filter_num=0\n",
    "activations = get_featuremaps(model, int(layer_num),test_image)\n",
    "print (np.shape(activations))\n",
    "feature_maps = activations[0][0]      \n",
    "print (np.shape(feature_maps))\n",
    "\n",
    "if K.image_data_format()=='th':\n",
    "\tfeature_maps=np.rollaxis((np.rollaxis(feature_maps,2,0)),2,0)\n",
    "print (feature_maps.shape)\n",
    "fig=plt.figure(figsize=(16,16))\n",
    "plt.imshow(feature_maps[:,:,filter_num])\n",
    "plt.savefig(\"featuremaps-layer-{}\".format(layer_num) + \"-filternum-{}\".format(filter_num)+'.jpg')\n",
    "\n",
    "num_of_featuremaps=feature_maps.shape[2]\n",
    "fig=plt.figure(figsize=(16,16))\t\n",
    "plt.title(\"featuremaps-layer-{}\".format(layer_num))\n",
    "subplot_num=int(np.ceil(np.sqrt(num_of_featuremaps)))\n",
    "for i in range(int(num_of_featuremaps)):\n",
    "\tax = fig.add_subplot(subplot_num, subplot_num, i+1)\n",
    "\tplt.xticks([])\n",
    "\tplt.yticks([])\n",
    "\tplt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"featuremaps-layer-{}\".format(layer_num) + '.jpg')\n",
    "\n",
    "# Printing the confusion matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import itertools\n",
    "Y_pred = model.predict(X_test)\n",
    "print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(y_pred)\n",
    "target_names = ['class 0(Bacterial_blight)', 'class 1(healthy)', 'class 2(leaf_minor)','class 3(spidermit)']\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = (confusion_matrix(np.argmax(y_test,axis=1), y_pred))\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names,\n",
    "                      title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "# Saving and loading model and weights of CDPDC\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "\n",
    "# Serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# Serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# Load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "model.save('model.hdf5')\n",
    "loaded_model=load_model('model.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
